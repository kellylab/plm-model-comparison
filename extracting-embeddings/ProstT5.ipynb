{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2HfYVcHaZ5u9gzTbTtOuB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pikanaeri/plm-model-comparison/blob/main/extracting-embeddings/ProstT5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Template Code for Extracting Averaged and Final Embeddings for each Model\n",
        "- Stores the embeddings as .pkl files\n",
        "- Final embeddings are stored in lists of vectors\n",
        "- Will need the PHROGs annotation table: https://storage.cloud.google.com/plm-model-comparison/PHROG_index.tsv"
      ],
      "metadata": {
        "id": "Ok76Xnx2Ih1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up Virtual Machine"
      ],
      "metadata": {
        "id": "cT3ReXVPI8gx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmJMFMzzIS2o"
      },
      "outputs": [],
      "source": [
        "#@title Tmux Setup (optional; so that your background processes save)\n",
        "sudo apt-get update -qq\n",
        "sudo apt-get install -y tmux\n",
        "tmux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XA1ukjFZob-r"
      },
      "outputs": [],
      "source": [
        "#@title Downloading Anaconda\n",
        "#@markdown * If a popup menu appears, chose the \"package maintainer's version\" option\n",
        "#@markdown * A menu containing all of Anaconda's terms of service will appear, go through these and select \"yes\" to download Anaconda to your computer\n",
        "#@markdown * An older version of Anaconda (2022) will be downloaded, keep this in mind when checking for compatible packages\n",
        "sudo apt-get update\n",
        "sudo apt-get install bzip2 libxml2-dev\n",
        "sudo apt upgrade\n",
        "\n",
        "sudo apt-get install wget\n",
        "wget https://repo.anaconda.com/archive/Anaconda3-2022.05-Linux-x86_64.sh\n",
        "bash Anaconda3-2022.05-Linux-x86_64.sh\n",
        "rm Anaconda3-2022.05-Linux-x86_64.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCSv9-pXob-s"
      },
      "outputs": [],
      "source": [
        "#@title Allocating Memory to Linux\n",
        "#@markdown Code from: https://linuxize.com/post/create-a-linux-swap-file/\n",
        "sudo fallocate -l 15G /swapfile\n",
        "sudo chmod 600 /swapfile\n",
        "ls -lh /swapfile\n",
        "sudo mkswap /swapfile\n",
        "sudo swapon /swapfile\n",
        "\n",
        "\n",
        "#@markdown Append \"/swapfile swap swap defaults 0 0\" to the /etc/fstab file using a text editor of your choice\n",
        "sudo nano /etc/fstab\n",
        "/swapfile swap swap defaults 0 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jii2XWT8ob-t"
      },
      "outputs": [],
      "source": [
        "#@title Installing Github\n",
        "sudo apt-get install git\n",
        "sudo apt install python3-pip\n",
        "\n",
        "python3 --version\n",
        "pip3 --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cloning PHROGs Database; files can also be found under the Fasta Files category at https://phrogs.lmge.uca.fr/\n",
        "git clone https://github.com/pikanaeri/Extracting-3Di-Embeddings-from-Protein-Sequences.git"
      ],
      "metadata": {
        "id": "XUXDnbCWKe9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MxlyXmRob-t",
        "outputId": "2255fc71-e8cf-4819-c1d8-63207c628858"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.35.0\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: sentencepiece, accelerate\n",
            "Successfully installed accelerate-0.24.1 sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "#@title Installing Dependencies\n",
        "pip install transformers\n",
        "pip3 install torch torchvision torchaudio transformers sentencepiece accelerate --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "\n",
        "mkdir final_embeddings\n",
        "mkdir final_average_embeddings\n",
        "python3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ProstT5 Embedding Extraction\n",
        "- Maximum Sequence Size 5096"
      ],
      "metadata": {
        "id": "TLOi44AsU_81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Importing Dependencies\n",
        "from transformers import T5Tokenizer, T5EncoderModel\n",
        "import torch\n",
        "import re\n",
        "import time\n",
        "import gc\n",
        "import numpy as np\n",
        "import pickle as pkl"
      ],
      "metadata": {
        "id": "HRdYnEaxqRaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Creating model and setting device to CPU if available\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device: {}\".format(device))\n",
        "transformer_link = \"Rostlab/ProstT5\"\n",
        "print(\"Loading: {}\".format(transformer_link))\n",
        "model = T5EncoderModel.from_pretrained(transformer_link)\n",
        "model.full() if device=='cpu' else model.half()\n",
        "model = model.to(device)\n",
        "model = model.eval()\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(transformer_link, do_lower_case=False )"
      ],
      "metadata": {
        "id": "owvzQJ2tqTmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQnqZIbfwo3V",
        "outputId": "3f7c9842-ca54-4966-db39-efe821a0dc26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda:0\n",
            "Loading: Rostlab/ProstT5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.06506   0.05774  -0.01139  ...  0.02162  -0.0612   -0.06143 ]\n",
            " [-0.061     0.07007   0.02899  ...  0.02339  -0.04446  -0.0517  ]\n",
            " [-0.04413   0.04855   0.02495  ...  0.01591  -0.04044  -0.0746  ]\n",
            " ...\n",
            " [-0.02856   0.02895   0.01654  ... -0.003574 -0.02275  -0.0258  ]\n",
            " [-0.013054  0.05884  -0.006424 ... -0.006264 -0.03583  -0.0313  ]\n",
            " [-0.07      0.07916   0.00418  ... -0.009865 -0.03995  -0.05136 ]]\n",
            "669\n",
            "1024\n",
            "[-0.0336    0.03876   0.00395  ... -0.002712 -0.04007  -0.06192 ]\n"
          ]
        }
      ],
      "source": [
        "#@title Embedding Families\n",
        "\n",
        "def embed_family(Prev_dir, File_Name, max_prot=-1, max_gsz=1, max_sz=-1):\n",
        "  reader = open(Prev_dir + File_Name + \".faa\", \"r\")\n",
        "  sequence_examples = []\n",
        "  final_embedding = []\n",
        "  num_proteins = 0\n",
        "  gsz = 0\n",
        "  while True:\n",
        "    name = reader.readline().strip()\n",
        "    if name == '':\n",
        "      break\n",
        "    sequence = reader.readline().strip()\n",
        "    sequence = sequence.replace('-', 'X')\n",
        "    if max_sz == -1 or len(sequence) <= max_sz:\n",
        "      sequence_examples.append(sequence)\n",
        "      num_proteins += 1\n",
        "      gsz += 1\n",
        "      if max_prot != -1 and num_proteins >= max_prot:\n",
        "        break\n",
        "    if gsz >= max_gsz:\n",
        "      sequence_examples = [\" \".join(list(re.sub(\"[UZOB]\", \"X\", sequence))) for sequence in sequence_examples]\n",
        "      ids = tokenizer.batch_encode_plus(sequence_examples, add_special_tokens=True, padding=\"longest\")\n",
        "      input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "      attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
        "      with torch.no_grad():\n",
        "          embedding_repr = model(input_ids=input_ids,attention_mask=attention_mask)\n",
        "      gc.collect()\n",
        "      torch.cuda.empty_cache()\n",
        "      for id in range(gsz):\n",
        "        emb = embedding_repr.last_hidden_state[id, :len(sequence_examples[id])]\n",
        "        emb = emb.mean(dim=0)\n",
        "        emb = emb.cpu().numpy()\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        final_embedding.append(np.array(emb))\n",
        "      gsz = 0\n",
        "      sequence_examples = []\n",
        "\n",
        "  if len(sequence_examples) > 0:\n",
        "    sequence_examples = [\" \".join(list(re.sub(\"[UZOB]\", \"X\", sequence))) for sequence in sequence_examples]\n",
        "    ids = tokenizer.batch_encode_plus(sequence_examples, add_special_tokens=True, padding=\"longest\")\n",
        "    input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "    attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
        "    with torch.no_grad():\n",
        "        embedding_repr = model(input_ids=input_ids,attention_mask=attention_mask)\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    for id in range(gsz):\n",
        "      emb = embedding_repr.last_hidden_state[id, :len(sequence_examples[id])]\n",
        "      emb = emb.mean(dim=0)\n",
        "      emb = emb.cpu().numpy()\n",
        "      gc.collect()\n",
        "      torch.cuda.empty_cache()\n",
        "      final_embedding.append(np.array(emb))\n",
        "      num_proteins += 1\n",
        "\n",
        "  reader.close()\n",
        "  outp_dir = File_Name + \".pkl\"\n",
        "  final_embedding = np.array(final_embedding)\n",
        "\n",
        "  with open(outp_dir, 'wb') as f:\n",
        "    pkl.dump(final_embedding, f)\n",
        "  outp_dir = File_Name + \"_averaged.pkl\"\n",
        "  av_embedding = np.mean(final_embedding, axis=0)\n",
        "  with open(outp_dir, 'wb') as f:\n",
        "    pkl.dump(av_embedding, f)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def nav_dir(rg_st=-1, family_cap=-1, prot_cap=-1, sz_cap=-1, File_Name = \"PHROG_index.tsv\"):\n",
        "  reader = open(File_Name, \"r\")\n",
        "  labels = reader.readline().strip().split(\"\\t\")\n",
        "  cnt = rg_st\n",
        "  while True:\n",
        "    line = reader.readline()\n",
        "    if line == '':\n",
        "      break\n",
        "    information = line.strip().split(\"\\t\")\n",
        "    phrog_num = int(information[0].split(\"phrog_\")[1])\n",
        "    if information[6] != 'unknown function' and phrog_num >= rg_st:\n",
        "      tm_start = time.perf_counter()\n",
        "      phrog_file = \"phrog_\" + str(phrog_num)\n",
        "      embed_family(\"\", phrog_file, max_prot=prot_cap, max_sz=sz_cap)\n",
        "      cnt += 1\n",
        "      if family_cap != -1 and cnt >= family_cap:\n",
        "        break\n",
        "      print(cnt, \" extracted!\")\n",
        "      print(\"took \", str((time.perf_counter()-tm_start)/60), \" minutes\")\n",
        "  reader.close()\n",
        "\n",
        "\n",
        "nav_dir()\n"
      ]
    }
  ]
}